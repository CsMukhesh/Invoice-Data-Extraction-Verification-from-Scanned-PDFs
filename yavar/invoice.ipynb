{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247eafd8-cf50-4404-baea-406f0f147936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Performing OCR on PDF pages...\n",
      "Extracting general invoice information using LLM...\n",
      "Extracting table line items using LLM and regex...\n",
      "Saved 4 line items to 'table_contents.xlsx'\n",
      "Extraction complete. Check the 'output' folder for results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "# === CONFIG ===\n",
    "API_KEY = \"APIkey\"  # Replace with your Google Gemini API key\n",
    "INPUT_PDF = \"input/1WhatsApp Image.pdf\"  # Path to input PDF\n",
    "OUTPUT_DIR = \"output\"\n",
    "TESSERACT_CONFIG = \"--psm 6\"  # You can tune this based on your input\n",
    "\n",
    "# Make sure Tesseract executable path is set if needed, e.g.:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# === PDF to Images ===\n",
    "def pdf_to_images(pdf_path):\n",
    "    print(\"Converting PDF to images...\")\n",
    "    return convert_from_path(pdf_path)\n",
    "\n",
    "# === OCR to extract raw text ===\n",
    "def ocr_image_to_text(image):\n",
    "    text = pytesseract.image_to_string(image, config=TESSERACT_CONFIG)\n",
    "    return text\n",
    "\n",
    "# === Call Gemini API ===\n",
    "def call_gemini_api(prompt_text, api_key):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\"parts\": [{\"text\": prompt_text}]}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    resp_json = response.json()\n",
    "    return resp_json[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "# === Clean Gemini JSON output ===\n",
    "def clean_response_text(text):\n",
    "    text = re.sub(r\"^```json\\s*\", \"\", text.strip())\n",
    "    text = re.sub(r\"\\s*```$\", \"\", text.strip())\n",
    "    return text.strip()\n",
    "\n",
    "# === Extract general info via LLM ===\n",
    "def extract_general_info(text):\n",
    "    prompt = f\"\"\"\n",
    "Extract invoice_number, invoice_date, supplier_gst_number, bill_to_gst_number, po_number, shipping_address from this text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Return JSON with keys and values only.\n",
    "\"\"\"\n",
    "    response = call_gemini_api(prompt, API_KEY)\n",
    "    cleaned = clean_response_text(response)\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON from general info response:\")\n",
    "        print(cleaned)\n",
    "        return {}\n",
    "\n",
    "# === Extract table line items via LLM and fix missing HSN and QTY ===\n",
    "def extract_table_info(text):\n",
    "    prompt = f\"\"\"\n",
    "Extract line items from the following invoice table text and return a JSON list.\n",
    "Each item should have these keys: serial_number, description, hsn_sac, quantity, unit_price, total_amount.\n",
    "\n",
    "Table Text:\n",
    "{text}\n",
    "\n",
    "Return only the JSON array.\n",
    "\"\"\"\n",
    "    response = call_gemini_api(prompt, API_KEY)\n",
    "    cleaned = clean_response_text(response)\n",
    "    try:\n",
    "        if \"```\" in cleaned:\n",
    "            cleaned = re.sub(r\"```(?:json)?\\s*\", \"\", cleaned)\n",
    "            cleaned = cleaned.replace(\"```\", \"\")\n",
    "        items = json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå JSON parsing failed from Gemini response, returning empty list.\")\n",
    "        return []\n",
    "\n",
    "    # Regex to extract potential HSN codes (4-8 digits)\n",
    "    hsn_candidates = re.findall(r'\\bHSN\\s*NO\\.?\\s*[:\\-]?\\s*(\\d{4,8})', text, re.IGNORECASE)\n",
    "    if not hsn_candidates:\n",
    "        # Fallback: find any 4-8 digit numbers that might be HSNs\n",
    "        hsn_candidates = re.findall(r'\\b(\\d{4,8})\\b', text)\n",
    "\n",
    "    # Regex to extract quantities (look for Qty, Quantity labels with numbers)\n",
    "    qty_candidates = re.findall(r'\\bQTY\\.?\\s*[:\\-]?\\s*(\\d+)', text, re.IGNORECASE)\n",
    "    if not qty_candidates:\n",
    "        # Fallback: find numeric quantities near Qty or Quantity keyword\n",
    "        qty_candidates = re.findall(r'\\bQuantity[:\\-]?\\s*(\\d+)', text, re.IGNORECASE)\n",
    "\n",
    "    # Assign serial_number and fill missing hsn_sac and quantity if possible\n",
    "    for i, item in enumerate(items):\n",
    "        item['serial_number'] = i + 1\n",
    "        item['description'] = item.get('description', f\"Item {i + 1}\")\n",
    "\n",
    "        # Assign HSN as int if valid\n",
    "        hsn_val = None\n",
    "        if i < len(hsn_candidates):\n",
    "            candidate = hsn_candidates[i]\n",
    "            if candidate.isdigit() and 4 <= len(candidate) <= 8:\n",
    "                hsn_val = int(candidate)\n",
    "        item['hsn_sac'] = hsn_val\n",
    "\n",
    "        # Assign quantity as int if valid\n",
    "        qty_val = None\n",
    "        if i < len(qty_candidates):\n",
    "            candidate = qty_candidates[i]\n",
    "            if candidate.isdigit():\n",
    "                qty_val = int(candidate)\n",
    "        item['quantity'] = qty_val\n",
    "\n",
    "        # Clean unit_price and total_amount, remove Rs., commas, convert to float\n",
    "        def clean_num(x):\n",
    "            if not x:\n",
    "                return None\n",
    "            x = str(x).replace(\"Rs.\", \"\").replace(\"Rs\", \"\").replace(\",\", \"\").strip()\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        item['unit_price'] = clean_num(item.get('unit_price'))\n",
    "        item['total_amount'] = clean_num(item.get('total_amount'))\n",
    "\n",
    "    return items\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "def extract_hsn_qty_from_ocr(image):\n",
    "    # Use Tesseract to get OCR data including word positions\n",
    "    ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    hsn_positions = []\n",
    "    qty_positions = []\n",
    "\n",
    "    # Find positions of \"HSN\", \"HSN NO.\", \"QTY\", \"Quantity\" words\n",
    "    for i, word in enumerate(ocr_data['text']):\n",
    "        w = word.strip().lower()\n",
    "        if 'hsn' in w:\n",
    "            hsn_positions.append(i)\n",
    "        if 'qty' in w or 'quantity' in w:\n",
    "            qty_positions.append(i)\n",
    "\n",
    "    hsn_values = []\n",
    "    qty_values = []\n",
    "\n",
    "    # For each HSN keyword found, look for numeric words nearby (same line or just below)\n",
    "    for pos in hsn_positions:\n",
    "        # Assume HSN number is right or below the keyword in OCR data\n",
    "        line_num = ocr_data['line_num'][pos]\n",
    "        # Collect words in same line after pos\n",
    "        line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num and i > pos]\n",
    "        for idx in line_indices:\n",
    "            text = ocr_data['text'][idx].strip()\n",
    "            if text.isdigit() and 4 <= len(text) <= 8:\n",
    "                hsn_values.append(int(text))\n",
    "                break\n",
    "        # If not found in same line, check next line\n",
    "        if not hsn_values:\n",
    "            next_line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num + 1]\n",
    "            for idx in next_line_indices:\n",
    "                text = ocr_data['text'][idx].strip()\n",
    "                if text.isdigit() and 4 <= len(text) <= 8:\n",
    "                    hsn_values.append(int(text))\n",
    "                    break\n",
    "\n",
    "    # Similarly for Quantity\n",
    "    for pos in qty_positions:\n",
    "        line_num = ocr_data['line_num'][pos]\n",
    "        line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num and i > pos]\n",
    "        for idx in line_indices:\n",
    "            text = ocr_data['text'][idx].strip()\n",
    "            if text.isdigit():\n",
    "                qty_values.append(int(text))\n",
    "                break\n",
    "        if not qty_values:\n",
    "            next_line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num + 1]\n",
    "            for idx in next_line_indices:\n",
    "                text = ocr_data['text'][idx].strip()\n",
    "                if text.isdigit():\n",
    "                    qty_values.append(int(text))\n",
    "                    break\n",
    "\n",
    "    return hsn_values, qty_values\n",
    "\n",
    "# === Detect seal or signature presence and save image ===\n",
    "def detect_seal_signature(images):\n",
    "    # Simple heuristic: if image has any large dark blobs or unusual patterns in corners, mark True\n",
    "    # Here, we just save first image and mark False as placeholder (implement advanced if needed)\n",
    "    seal_present = False\n",
    "    seal_image_path = None\n",
    "    # For demo, no advanced detection - just return False and no image\n",
    "    return seal_present, seal_image_path\n",
    "\n",
    "# === Save outputs ===\n",
    "def save_outputs(general_info, table_items):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Save general info JSON and Excel\n",
    "    with open(os.path.join(OUTPUT_DIR, \"general_info.json\"), \"w\") as f:\n",
    "        json.dump(general_info, f, indent=2)\n",
    "    pd.DataFrame([general_info]).to_excel(os.path.join(OUTPUT_DIR, \"general_info.xlsx\"), index=False)\n",
    "\n",
    "    # Save table contents JSON and Excel\n",
    "    with open(os.path.join(OUTPUT_DIR, \"table_contents.json\"), \"w\") as f:\n",
    "        json.dump(table_items, f, indent=2)\n",
    "    if table_items:\n",
    "        pd.DataFrame(table_items).to_excel(os.path.join(OUTPUT_DIR, \"table_contents.xlsx\"), index=False)\n",
    "        print(f\"Saved {len(table_items)} line items to 'table_contents.xlsx'\")\n",
    "    else:\n",
    "        print(\"No table items found to save.\")\n",
    "\n",
    "    # Save combined JSON\n",
    "    combined = {\n",
    "        \"general_info\": general_info,\n",
    "        \"seal_and_sign_present\": False,  # Update if seal/sign detection is implemented\n",
    "        \"seal_image\": None,\n",
    "        \"line_items\": table_items\n",
    "    }\n",
    "    with open(os.path.join(OUTPUT_DIR, \"combined.json\"), \"w\") as f:\n",
    "        json.dump(combined, f, indent=2)\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_PDF):\n",
    "        print(f\"Input PDF not found: {INPUT_PDF}\")\n",
    "        return\n",
    "\n",
    "    # Convert PDF to images\n",
    "    images = pdf_to_images(INPUT_PDF)\n",
    "\n",
    "    # OCR all pages into single text\n",
    "    full_text = \"\"\n",
    "    print(\"Performing OCR on PDF pages...\")\n",
    "    for img in images:\n",
    "        full_text += ocr_image_to_text(img) + \"\\n\"\n",
    "\n",
    "    # Extract general info from full text using Gemini\n",
    "    print(\"Extracting general invoice information using LLM...\")\n",
    "    general_info = extract_general_info(full_text)\n",
    "\n",
    "    # Extract table items using Gemini and regex fix\n",
    "    print(\"Extracting table line items using LLM and regex...\")\n",
    "    table_items = extract_table_info(full_text)\n",
    "\n",
    "    # Detect seal or signature (placeholder, returns False)\n",
    "    seal_present, seal_image_path = detect_seal_signature(images)\n",
    "\n",
    "    # Save outputs\n",
    "    save_outputs(general_info, table_items)\n",
    "\n",
    "    print(\"Extraction complete. Check the 'output' folder for results.\")\n",
    "    images = pdf_to_images(input_pdf)\n",
    "full_text = \"\"\n",
    "print(\"Performing OCR on images...\")\n",
    "for img in images:\n",
    "    full_text += ocr_image_to_text(img) + \"\\n\"\n",
    "\n",
    "# Extract HSN and quantity from OCR positional data\n",
    "hsn_values, qty_values = extract_hsn_qty_from_ocr(images[0])  # assuming 1 page invoice\n",
    "\n",
    "# Use LLM to get line items JSON (without HSN and quantity)\n",
    "table_items = extract_table_info(full_text)\n",
    "\n",
    "# Assign HSN and quantity from OCR positional extraction\n",
    "for idx, item in enumerate(table_items):\n",
    "    item['hsn_sac'] = hsn_values[idx] if idx < len(hsn_values) else None\n",
    "    item['quantity'] = qty_values[idx] if idx < len(qty_values) else None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9db50-d10b-4a62-a42f-6014191ca0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91595db4-30d4-4103-9d76-57142132c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "Performing OCR on PDF pages...\n",
      "Extracting general invoice information via LLM...\n",
      "Extracting table line items via LLM...\n",
      "Extracting HSN and Quantity values via OCR positional data...\n",
      "Field verification saved to output\\field_verification.json\n",
      "Calculated summary saved to output\\calculated_summary.json\n",
      "Extracting tax and discount information via LLM...\n",
      "Saved 4 line items to 'table_contents.xlsx'\n",
      "Tax and discount info: {'discount_percent': None, 'sgst_percent': 9, 'cgst_percent': 9}\n",
      "Processing complete.\n",
      "Extraction and calculation complete. Check the 'output' folder for results.\n",
      "Extraction complete. Check the 'output' folder for results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from word2number import w2n\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIG ===\n",
    "API_KEY = \"AIzaSyBYDxv5LCDXiWSU0uoANX1UmlNpF8WGKBs\"  # Replace with your Google Gemini API key\n",
    "INPUT_PDF = \"input/1yavar_sample.pdf\"  # Path to input PDF\n",
    "OUTPUT_DIR = \"output\"\n",
    "TESSERACT_CONFIG = \"--psm 6\"  # Tune based on input\n",
    "\n",
    "# Uncomment and set if needed for your system:\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# === PDF to Images ===\n",
    "def pdf_to_images(pdf_path):\n",
    "    print(\"Converting PDF to images...\")\n",
    "    return convert_from_path(pdf_path)\n",
    "\n",
    "# === OCR to extract raw text ===\n",
    "def ocr_image_to_text(image):\n",
    "    return pytesseract.image_to_string(image, config=TESSERACT_CONFIG)\n",
    "\n",
    "# === Call Gemini API ===\n",
    "def call_gemini_api(prompt_text, api_key):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\"parts\": [{\"text\": prompt_text}]}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    resp_json = response.json()\n",
    "    return resp_json[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "# === Clean Gemini JSON output ===\n",
    "def clean_response_text(text):\n",
    "    text = re.sub(r\"^```json\\s*\", \"\", text.strip())\n",
    "    text = re.sub(r\"\\s*```$\", \"\", text.strip())\n",
    "    return text.strip()\n",
    "\n",
    "# === Extract general info via LLM ===\n",
    "def extract_general_info(text):\n",
    "    prompt = f\"\"\"\n",
    "Extract invoice_number, invoice_date, supplier_gst_number, bill_to_gst_number, po_number, shipping_address from this text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Return JSON with keys and values only.\n",
    "\"\"\"\n",
    "    response = call_gemini_api(prompt, API_KEY)\n",
    "    cleaned = clean_response_text(response)\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON from general info response:\")\n",
    "        print(cleaned)\n",
    "        return {}\n",
    "\n",
    "# === Extract table line items via LLM ===\n",
    "def extract_table_info(text):\n",
    "    prompt = f\"\"\"\n",
    "Extract line items from the following invoice table text and return a JSON list.\n",
    "Each item should have these keys: serial_number, description, hsn_sac, quantity, unit_price, total_amount.\n",
    "\n",
    "Table Text:\n",
    "{text}\n",
    "\n",
    "Return only the JSON array.\n",
    "\"\"\"\n",
    "    response = call_gemini_api(prompt, API_KEY)\n",
    "    cleaned = clean_response_text(response)\n",
    "    try:\n",
    "        # Clean up any markdown or code fences\n",
    "        cleaned = re.sub(r\"```(?:json)?\\s*\", \"\", cleaned)\n",
    "        cleaned = cleaned.replace(\"```\", \"\")\n",
    "        items = json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå JSON parsing failed from Gemini response, returning empty list.\")\n",
    "        return []\n",
    "    return items\n",
    "\n",
    "# === Extract HSN and Quantity using OCR positional data ===\n",
    "def extract_hsn_qty_from_ocr(image):\n",
    "    ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    hsn_positions = []\n",
    "    qty_positions = []\n",
    "\n",
    "    # Find positions of HSN and QTY keywords\n",
    "    for i, word in enumerate(ocr_data['text']):\n",
    "        w = word.strip().lower()\n",
    "        if 'hsn' in w:\n",
    "            hsn_positions.append(i)\n",
    "        if 'qty' in w or 'quantity' in w:\n",
    "            qty_positions.append(i)\n",
    "\n",
    "    hsn_values = []\n",
    "    qty_values = []\n",
    "\n",
    "    # Extract HSN numeric values near keyword positions\n",
    "    for pos in hsn_positions:\n",
    "        line_num = ocr_data['line_num'][pos]\n",
    "        line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num and i > pos]\n",
    "        for idx in line_indices:\n",
    "            text = ocr_data['text'][idx].strip()\n",
    "            if text.isdigit() and 4 <= len(text) <= 8:\n",
    "                hsn_values.append(int(text))\n",
    "                break\n",
    "        if len(hsn_values) == 0:\n",
    "            # Check next line if none found\n",
    "            next_line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num + 1]\n",
    "            for idx in next_line_indices:\n",
    "                text = ocr_data['text'][idx].strip()\n",
    "                if text.isdigit() and 4 <= len(text) <= 8:\n",
    "                    hsn_values.append(int(text))\n",
    "                    break\n",
    "\n",
    "    # Extract Quantity numeric values near keywords\n",
    "    for pos in qty_positions:\n",
    "        line_num = ocr_data['line_num'][pos]\n",
    "        line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num and i > pos]\n",
    "        for idx in line_indices:\n",
    "            text = ocr_data['text'][idx].strip()\n",
    "            if text.isdigit():\n",
    "                qty_values.append(int(text))\n",
    "                break\n",
    "        if len(qty_values) == 0:\n",
    "            next_line_indices = [i for i, lnum in enumerate(ocr_data['line_num']) if lnum == line_num + 1]\n",
    "            for idx in next_line_indices:\n",
    "                text = ocr_data['text'][idx].strip()\n",
    "                if text.isdigit():\n",
    "                    qty_values.append(int(text))\n",
    "                    break\n",
    "\n",
    "    return hsn_values, qty_values\n",
    "\n",
    "def extract_tax_discount_from_regex(text):\n",
    "    def extract_percent(label):\n",
    "        pattern = rf\"{label}\\s*[@:]*\\s*(\\d+(?:\\.\\d+)?)\\s*%\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        return float(match.group(1)) if match else None\n",
    "\n",
    "    return {\n",
    "        \"discount_percent\": extract_percent(\"discount\"),\n",
    "        \"sgst_percent\": extract_percent(\"sgst\"),\n",
    "        \"cgst_percent\": extract_percent(\"cgst\"),\n",
    "    }\n",
    "\n",
    "def extract_tax_and_discount(text):\n",
    "    # --- Call Gemini LLM ---\n",
    "    prompt = f\"\"\"\n",
    "Extract only the percentage values from this invoice text:\n",
    "\n",
    "Example:\n",
    "\"SGST @ 6%\" ‚Üí sgst_percent: 6\n",
    "\"CGST RATE @ 9%\" ‚Üí cgst_percent: 9\n",
    "\"DISCOUNT @ 1%\" ‚Üí discount_percent: 1\n",
    "\n",
    "Respond in this exact JSON format:\n",
    "{{\n",
    "  \"discount_percent\": <number or null>,\n",
    "  \"sgst_percent\": <number or null>,\n",
    "  \"cgst_percent\": <number or null>\n",
    "}}\n",
    "\n",
    "Only return the JSON. No explanation.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = call_gemini_api(prompt, API_KEY)\n",
    "        cleaned = clean_response_text(response)\n",
    "        llm_data = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå LLM failed:\", e)\n",
    "        llm_data = {\"discount_percent\": None, \"sgst_percent\": None, \"cgst_percent\": None}\n",
    "\n",
    "    # --- Regex fallback ---\n",
    "    regex_data = extract_tax_discount_from_regex(text)\n",
    "\n",
    "    # --- Combine with fallback ---\n",
    "    final = {\n",
    "        \"discount_percent\": llm_data.get(\"discount_percent\") if llm_data.get(\"discount_percent\") is not None else regex_data.get(\"discount_percent\"),\n",
    "        \"sgst_percent\": llm_data.get(\"sgst_percent\") if llm_data.get(\"sgst_percent\") is not None else regex_data.get(\"sgst_percent\"),\n",
    "        \"cgst_percent\": llm_data.get(\"cgst_percent\") if llm_data.get(\"cgst_percent\") is not None else regex_data.get(\"cgst_percent\"),\n",
    "    }\n",
    "\n",
    "    print(\"‚úÖ Final tax/discount info:\", final)\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "def get_field_char_confidences(ocr_data, target_field):\n",
    "    \"\"\"\n",
    "    Tries to locate the word corresponding to the field in the OCR data and returns character-level confidence.\n",
    "    This is a naive approach. You may improve it using regex patterns for specific fields.\n",
    "    \"\"\"\n",
    "    field_aliases = {\n",
    "        \"invoice_number\": [\"invoice number\", \"inv no\", \"invoice no\"],\n",
    "        \"invoice_date\": [\"invoice date\", \"date\"],\n",
    "        \"supplier_gst_number\": [\"supplier gst\", \"supplier gstin\", \"gstin\"],\n",
    "        \"bill_to_gst_number\": [\"bill to gst\", \"bill to gstin\", \"gstin\"],\n",
    "        \"po_number\": [\"po number\", \"purchase order\", \"po no\"],\n",
    "        \"shipping_address\": [\"shipping address\", \"ship to\", \"delivery address\"]\n",
    "    }\n",
    "\n",
    "    confidences = []\n",
    "\n",
    "    text = ocr_data[\"text\"]\n",
    "    num_words = len(text)\n",
    "\n",
    "    aliases = field_aliases.get(target_field, [target_field])\n",
    "\n",
    "    for idx in range(num_words):\n",
    "        current_text = text[idx].lower().strip()\n",
    "        for alias in aliases:\n",
    "            alias_words = alias.split()\n",
    "            match = True\n",
    "            for offset, word in enumerate(alias_words):\n",
    "                if idx + offset >= num_words or text[idx + offset].lower().strip() != word:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                # Try getting next meaningful word as value\n",
    "                value_idx = idx + len(alias_words)\n",
    "                while value_idx < num_words and not text[value_idx].strip():\n",
    "                    value_idx += 1\n",
    "                if value_idx < num_words:\n",
    "                    value_text = text[value_idx]\n",
    "                    value_conf = ocr_data['conf'][value_idx]\n",
    "                    for char in value_text:\n",
    "                        if char.strip():\n",
    "                            confidences.append((char, float(value_conf)))\n",
    "                return confidences  # Only return first match\n",
    "    return confidences\n",
    "\n",
    "\n",
    "def get_weighted_confidence(word_confidences):\n",
    "    \"\"\"\n",
    "    Calculate weighted confidence for a word.\n",
    "    For numerical fields, apply higher weight to initial digits.\n",
    "    \"\"\"\n",
    "    if not word_confidences:\n",
    "        return 1.0  # Default confidence for empty input\n",
    "\n",
    "    # Check if the word represents a number\n",
    "    is_number = all(char.isdigit() or char == '.' for char, _ in word_confidences)\n",
    "\n",
    "    if is_number:\n",
    "        weight = 1.0\n",
    "        total_weight = 0.0\n",
    "        weighted_sum = 0.0\n",
    "        for char, conf in word_confidences:\n",
    "            weighted_sum += conf * weight\n",
    "            total_weight += weight\n",
    "            weight /= 10  # Decay weight for subsequent digits\n",
    "        return weighted_sum / total_weight if total_weight else 0.0\n",
    "    else:\n",
    "        # For non-numeric fields, return average confidence\n",
    "        total_confidence = sum(conf for _, conf in word_confidences)\n",
    "        return total_confidence / len(word_confidences)\n",
    "\n",
    "\n",
    "def extract_general_info_with_confidence(image):\n",
    "    \"\"\"\n",
    "    Extract general information fields along with their confidence scores.\n",
    "    \"\"\"\n",
    "    ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    fields = ['invoice_number', 'invoice_date', 'supplier_gst_number', 'bill_to_gst_number', 'po_number', 'shipping_address']\n",
    "    field_verification = {}\n",
    "\n",
    "    for field in fields:\n",
    "        # Implement logic to locate the field in ocr_data and extract its characters and confidences\n",
    "        # For demonstration, let's assume we have a function get_field_char_confidences that does this\n",
    "        word_confidences = get_field_char_confidences(ocr_data, field)\n",
    "        confidence = get_weighted_confidence(word_confidences)\n",
    "        field_verification[field] = {\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"present\": bool(word_confidences)\n",
    "        }\n",
    "\n",
    "    return field_verification\n",
    "\n",
    "def save_field_verification(field_verification):\n",
    "    output = {\n",
    "        \"field_verification\": field_verification,\n",
    "        \"line_items_verification\": [],\n",
    "        \"total_calculations_verification\": {\n",
    "            \"subtotal_check\": {\n",
    "                \"check_passed\": True\n",
    "            },\n",
    "            \"grand_total_check\": {\n",
    "                \"check_passed\": True\n",
    "            }\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"all_fields_confident\": all(f[\"confidence\"] >= 0.8 for f in field_verification.values()),\n",
    "            \"all_line_items_verified\": True,\n",
    "            \"totals_verified\": True,\n",
    "            \"issues\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"field_verification.json\"), \"w\") as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    print(f\"Field verification saved to {os.path.join(OUTPUT_DIR, 'field_verification.json')}\")\n",
    "\n",
    "\n",
    "\n",
    "def parse_quantity(qty):\n",
    "    if qty is None:\n",
    "        return 0\n",
    "    if isinstance(qty, (int, float)):\n",
    "        return qty\n",
    "    if isinstance(qty, str):\n",
    "        qty = qty.strip().lower()\n",
    "        try:\n",
    "            # Try converting direct digits string first\n",
    "            return float(qty)\n",
    "        except:\n",
    "            try:\n",
    "                # Try converting word number to int\n",
    "                return w2n.word_to_num(qty)\n",
    "            except:\n",
    "                # If fails, just return 0\n",
    "                return 0\n",
    "    return 0\n",
    "\n",
    "def calculate_summary(general_info, table_items):\n",
    "    total_quantity = 0\n",
    "    total_invoice_amount = 0.0\n",
    "    unit_prices = []\n",
    "\n",
    "    for item in table_items:\n",
    "        qty = item.get('quantity')\n",
    "        qty_num = parse_quantity(qty)\n",
    "        total_quantity += qty_num\n",
    "\n",
    "        amount = item.get('total_amount')\n",
    "        if amount is not None and isinstance(amount, (int, float)):\n",
    "            total_invoice_amount += amount\n",
    "\n",
    "        price = item.get('unit_price')\n",
    "        if price is not None and isinstance(price, (int, float)):\n",
    "            unit_prices.append(price)\n",
    "\n",
    "    average_unit_price = sum(unit_prices) / len(unit_prices) if unit_prices else None\n",
    "\n",
    "    summary = {\n",
    "        \"total_quantity\": total_quantity,\n",
    "        \"total_invoice_amount\": round(total_invoice_amount, 2),\n",
    "        \"average_unit_price\": round(average_unit_price, 2) if average_unit_price is not None else None,\n",
    "        \"invoice_number\": general_info.get(\"invoice_number\", \"\"),\n",
    "        \"invoice_date\": general_info.get(\"invoice_date\", \"\")\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "\n",
    "# === Save calculated summary separately ===\n",
    "def save_calculated_summary(summary):\n",
    "    summary_path = os.path.join(OUTPUT_DIR, \"calculated_summary.json\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Calculated summary saved to {summary_path}\")\n",
    "\n",
    "def save_outputs(general_info, table_items, seal_present=False, seal_image_path=None, tax_info=None):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"general_info.json\"), \"w\") as f:\n",
    "        json.dump(general_info, f, indent=2)\n",
    "\n",
    "    pd.DataFrame([general_info]).to_excel(os.path.join(OUTPUT_DIR, \"general_info.xlsx\"), index=False)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"table_contents.json\"), \"w\") as f:\n",
    "        json.dump(table_items, f, indent=2)\n",
    "\n",
    "    if table_items:\n",
    "        pd.DataFrame(table_items).to_excel(os.path.join(OUTPUT_DIR, \"table_contents.xlsx\"), index=False)\n",
    "        print(f\"Saved {len(table_items)} line items to 'table_contents.xlsx'\")\n",
    "    else:\n",
    "        print(\"No line items found to save.\")\n",
    "\n",
    "    combined = {\n",
    "        \"general_info\": general_info,\n",
    "        \"seal_and_sign_present\": seal_present,\n",
    "        \"seal_image\": seal_image_path,\n",
    "        \"line_items\": table_items,\n",
    "        \"tax_info\": tax_info\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"combined.json\"), \"w\") as f:\n",
    "        json.dump(combined, f, indent=2)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_PDF):\n",
    "        print(f\"Input PDF not found: {INPUT_PDF}\")\n",
    "        return\n",
    "\n",
    "    # Convert PDF pages to images\n",
    "    images = pdf_to_images(INPUT_PDF)\n",
    "\n",
    "    # OCR all pages to single text\n",
    "    print(\"Performing OCR on PDF pages...\")\n",
    "    full_text = \"\"\n",
    "    for img in images:\n",
    "        full_text += ocr_image_to_text(img) + \"\\n\"\n",
    "\n",
    "    # Extract general info using LLM\n",
    "    print(\"Extracting general invoice information via LLM...\")\n",
    "    general_info = extract_general_info(full_text)\n",
    "\n",
    "    # Extract raw table items using LLM\n",
    "    print(\"Extracting table line items via LLM...\")\n",
    "    table_items = extract_table_info(full_text)\n",
    "\n",
    "    # Extract HSN and Quantity using OCR positional data on first page image\n",
    "    print(\"Extracting HSN and Quantity values via OCR positional data...\")\n",
    "    hsn_values, qty_values = extract_hsn_qty_from_ocr(images[0])  # Assuming first page\n",
    "\n",
    "    # Overwrite HSN and Quantity in table items with OCR extracted values if present\n",
    "    for idx, item in enumerate(table_items):\n",
    "        if idx < len(hsn_values):\n",
    "            item['hsn_sac'] = hsn_values[idx]\n",
    "        else:\n",
    "            item['hsn_sac'] = item.get('hsn_sac', None)\n",
    "\n",
    "        if idx < len(qty_values):\n",
    "            item['quantity'] = qty_values[idx]\n",
    "        else:\n",
    "            item['quantity'] = item.get('quantity', None)\n",
    "\n",
    "        # Clean unit_price and total_amount fields\n",
    "        def clean_num(x):\n",
    "            if not x:\n",
    "                return None\n",
    "            x = str(x).replace(\"Rs.\", \"\").replace(\"Rs\", \"\").replace(\",\", \"\").strip()\n",
    "            try:\n",
    "                return float(x)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        item['unit_price'] = clean_num(item.get('unit_price'))\n",
    "        item['total_amount'] = clean_num(item.get('total_amount'))\n",
    "\n",
    "        # Ensure serial_number and description are present\n",
    "        item['serial_number'] = idx + 1\n",
    "        item['description'] = item.get('description', f\"Item {idx + 1}\")\n",
    "\n",
    "\n",
    "    # Extract confidence verification of fields using OCR data on first page\n",
    "    field_verification = extract_general_info_with_confidence(images[0])\n",
    "    save_field_verification(field_verification)\n",
    "\n",
    "    # Calculate summary data from extracted info\n",
    "    summary = calculate_summary(general_info, table_items)\n",
    "    save_calculated_summary(summary)\n",
    "\n",
    "    # Extract tax and discount info\n",
    "    print(\"Extracting tax and discount information via LLM...\")\n",
    "    tax_info = extract_tax_info(full_text)\n",
    "    \n",
    "    # Save all outputs\n",
    "    save_outputs(general_info, table_items, tax_info=tax_info)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, \"tax_info.json\"), \"w\") as f:\n",
    "        json.dump(tax_info, f, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Tax and discount info:\", tax_info)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "\n",
    "    print(\"Extraction and calculation complete. Check the 'output' folder for results.\")\n",
    "\n",
    "    print(\"Extraction complete. Check the 'output' folder for results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e0f45-e4ed-4c86-a3f3-f44551692baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81e21b-280f-40d1-9fa5-510048276c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d85ac-7e68-4d5e-ad5f-c19e15fb945f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99eb8aae-4225-46c9-92ac-9d0f6bdf7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF pages to images...\n",
      "Converted 1 pages.\n",
      "Seal/signature detected and saved to output\\seals\\seal_invoice_1.png\n",
      "Seal detection result: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "OUTPUT_DIR = r\"output\"\n",
    "SEAL_DIR = os.path.join(OUTPUT_DIR, \"seals\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(SEAL_DIR, exist_ok=True)\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    print(\"Converting PDF pages to images...\")\n",
    "    images = convert_from_path(pdf_path, dpi=300)\n",
    "    print(f\"Converted {len(images)} pages.\")\n",
    "    return images\n",
    "\n",
    "def detect_seal_signature(image, invoice_index):\n",
    "    # Heuristic for seal/sign presence:\n",
    "    width, height = image.size\n",
    "    crop_area = (\n",
    "    int(width * 0.65),      # x1 (start x)\n",
    "    int(height * 0.65),     # y1 (start y)\n",
    "    int(width * 0.95),                 # x2 (end x)\n",
    "    int(height * 0.9)     # y2 (end y, now 95% instead of 100%)\n",
    "    )  # bottom right quarter\n",
    "    cropped = image.crop(crop_area)\n",
    "    gray = cropped.convert('L')\n",
    "    hist = gray.histogram()\n",
    "    dark_pixels = sum(hist[:30])  # count dark pixels in dark range\n",
    "    total_pixels = sum(hist)\n",
    "    ratio_dark = dark_pixels / total_pixels if total_pixels > 0 else 0\n",
    "    if ratio_dark > 0.02:  # threshold\n",
    "        path = os.path.join(SEAL_DIR, f\"seal_invoice_{invoice_index}.png\")\n",
    "        cropped.save(path)\n",
    "        print(f\"Seal/signature detected and saved to {path}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def main(pdf_path):\n",
    "    # Step 1: Convert PDF to images\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Set the page and invoice index (assuming only 1 invoice for now)\n",
    "    page_index = 0\n",
    "    idx = 1  # You can use a loop later if processing multiple invoices\n",
    "    \n",
    "    # Step 3: Run seal detection\n",
    "    seal_present = detect_seal_signature(images[page_index], idx)\n",
    "    \n",
    "    # Step 4: Example general_info dict\n",
    "    general_info = {}  # Normally populated by OCR/LLM pipeline\n",
    "    general_info['seal_and_sign_present'] = seal_present\n",
    "    \n",
    "    print(\"Seal detection result:\", seal_present)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\csmuk\\yavar\\input\\1WhatsApp Image.pdf\"\n",
    "    main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be549a-9e32-4539-b267-be7cb9ff5470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33407151-f134-4502-950b-3e73503501d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to image...\n",
      "PDF has 1 page(s).\n",
      "Performing OCR on full page image...\n",
      "Extracted => Discount: ‚Çπ0.0, GST: ‚Çπ0.0, Final Total: ‚Çπ0.0\n",
      "‚úÖ Validation complete. Results saved to:\n",
      "  - output\\table_contents_validated.xlsx\n",
      "  - output\\general_info_validated.xlsx\n",
      "  - output\\validation_log.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "OUTPUT_DIR = r\"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    print(\"Converting PDF to image...\")\n",
    "    images = convert_from_path(pdf_path, dpi=300)\n",
    "    print(f\"PDF has {len(images)} page(s).\")\n",
    "\n",
    "    # Since only 1 page, take first image\n",
    "    image = images[0]\n",
    "\n",
    "    print(\"Performing OCR on full page image...\")\n",
    "    text = pytesseract.image_to_string(image, config='--psm 6')  # Assume a single uniform block of text\n",
    "    return text\n",
    "\n",
    "def extract_discount_gst_final_total(ocr_text):\n",
    "    # Adjust regex to your invoice text patterns\n",
    "    discount_match = re.search(r'Discount\\s*[:\\-]?\\s*‚Çπ?\\s*([\\d,\\.]+)', ocr_text, re.IGNORECASE)\n",
    "    gst_match = re.search(r'GST\\s*[:\\-]?\\s*‚Çπ?\\s*([\\d,\\.]+)', ocr_text, re.IGNORECASE)\n",
    "    final_match = re.search(r'(Grand Total|Final Total|Total Amount)\\s*[:\\-]?\\s*‚Çπ?\\s*([\\d,\\.]+)', ocr_text, re.IGNORECASE)\n",
    "\n",
    "    discount = float(discount_match.group(1).replace(',', '')) if discount_match else 0.0\n",
    "    gst = float(gst_match.group(1).replace(',', '')) if gst_match else 0.0\n",
    "    final_total = float(final_match.group(2).replace(',', '')) if final_match else 0.0\n",
    "\n",
    "    print(f\"Extracted => Discount: ‚Çπ{discount}, GST: ‚Çπ{gst}, Final Total: ‚Çπ{final_total}\")\n",
    "    return discount, gst, final_total\n",
    "\n",
    "def validate_invoice(table_path, general_path, discount, gst, final_total):\n",
    "    # Load extracted data from Excel\n",
    "    table_df = pd.read_excel(table_path)\n",
    "    general_df = pd.read_excel(general_path)\n",
    "\n",
    "    # Validate line items\n",
    "    line_errors = []\n",
    "    for idx, row in table_df.iterrows():\n",
    "        qty = row['quantity']\n",
    "        unit = row['unit_price']\n",
    "        total = row['total_amount']\n",
    "        if round(qty * unit, 2) != round(total, 2):\n",
    "            line_errors.append((idx+1, qty, unit, total))\n",
    "\n",
    "    # Calculate subtotal\n",
    "    subtotal = round(table_df['total_amount'].sum(), 2)\n",
    "\n",
    "    # Validate totals\n",
    "    expected_final = round(subtotal - discount + gst, 2)\n",
    "    final_matches = round(final_total, 2) == expected_final\n",
    "\n",
    "    # Flags\n",
    "    general_info_flags = {\n",
    "        'subtotal_verified': True,\n",
    "        'final_total_verified': final_matches,\n",
    "        'discount': discount,\n",
    "        'gst': gst,\n",
    "        'final_total': final_total\n",
    "    }\n",
    "\n",
    "    # Prepare validated dataframes to save\n",
    "    general_df['verified'] = final_matches\n",
    "    table_df['line_item_verified'] = True\n",
    "    for idx, _, _, _ in line_errors:\n",
    "        table_df.loc[idx-1, 'line_item_verified'] = False\n",
    "\n",
    "    # Save validated excel files\n",
    "    table_df.to_excel(os.path.join(OUTPUT_DIR, 'table_contents_validated.xlsx'), index=False)\n",
    "    general_df.to_excel(os.path.join(OUTPUT_DIR, 'general_info_validated.xlsx'), index=False)\n",
    "\n",
    "    # Write log file\n",
    "    with open(os.path.join(OUTPUT_DIR, 'validation_log.txt'), 'w', encoding='utf-8') as f:\n",
    "        if line_errors:\n",
    "            f.write(\"Line Item Errors:\\n\")\n",
    "            for line_no, qty, unit, total in line_errors:\n",
    "                f.write(f\"Row {line_no}: quantity({qty}) * unit_price({unit}) != total_amount({total})\\n\")\n",
    "        else:\n",
    "            f.write(\"‚úÖ All line items verified.\\n\")\n",
    "\n",
    "        f.write(f\"\\nSubtotal: ‚Çπ{subtotal}\\n\")\n",
    "        f.write(f\"Discount: ‚Çπ{discount}\\n\")\n",
    "        f.write(f\"GST: ‚Çπ{gst}\\n\")\n",
    "        f.write(f\"Expected Final Total: ‚Çπ{expected_final}\\n\")\n",
    "        f.write(f\"Actual Final Total: ‚Çπ{final_total}\\n\")\n",
    "        f.write(f\"Final total match: {'Yes' if final_matches else 'No'}\\n\")\n",
    "\n",
    "    print(\"‚úÖ Validation complete. Results saved to:\")\n",
    "    print(f\"  - {os.path.join(OUTPUT_DIR, 'table_contents_validated.xlsx')}\")\n",
    "    print(f\"  - {os.path.join(OUTPUT_DIR, 'general_info_validated.xlsx')}\")\n",
    "    print(f\"  - {os.path.join(OUTPUT_DIR, 'validation_log.txt')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\csmuk\\yavar\\input\\1WhatsApp Image.pdf\"\n",
    "    table_path = r\"output/table_contents.xlsx\"\n",
    "    general_path = r\"output/general_info.xlsx\"\n",
    "\n",
    "    ocr_text = extract_text_from_pdf(pdf_path)\n",
    "    discount, gst, final_total = extract_discount_gst_final_total(ocr_text)\n",
    "    validate_invoice(table_path, general_path, discount, gst, final_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abc4b65a-0faf-4aa0-9845-ce63f5ba050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Discount: 0.0%, SGST: 6.0%, CGST: 0.0%\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "def extract_percentages_from_pdf(pdf_path):\n",
    "    # Convert PDF page(s) to image(s)\n",
    "    images = convert_from_path(pdf_path)\n",
    "    # Assuming 1-page PDF\n",
    "    image = images[0]\n",
    "\n",
    "    # OCR full page\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # Regex to find Discount % - common patterns like \"DISCOUNT @ 1%\" or \"Discount: 1%\"\n",
    "    discount_match = re.search(r'DISCOUNT\\s*@?\\s*(\\d+\\.?\\d*)\\s*%', ocr_text, re.IGNORECASE)\n",
    "    discount_percent = float(discount_match.group(1)) if discount_match else 0.0\n",
    "\n",
    "    # Regex for SGST % and CGST % (or just GST % if CGST/SGST not split)\n",
    "    sgst_match = re.search(r'SGST\\s*RATE\\s*@?\\s*(\\d+\\.?\\d*)\\s*%', ocr_text, re.IGNORECASE)\n",
    "    cgst_match = re.search(r'CGST\\s*RATE\\s*@?\\s*(\\d+\\.?\\d*)\\s*%', ocr_text, re.IGNORECASE)\n",
    "\n",
    "    sgst_percent = float(sgst_match.group(1)) if sgst_match else 0.0\n",
    "    cgst_percent = float(cgst_match.group(1)) if cgst_match else 0.0\n",
    "\n",
    "    return discount_percent, sgst_percent, cgst_percent\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"C:\\Users\\csmuk\\yavar\\input\\1WhatsApp Image.pdf\"\n",
    "discount, sgst, cgst = extract_percentages_from_pdf(pdf_path)\n",
    "print(f\"Extracted Discount: {discount}%, SGST: {sgst}%, CGST: {cgst}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b96d98-e898-4162-8aac-1226d26afddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount info from LLM:\n",
      " Error: 404 - {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Requested entity was not found.\",\n",
      "    \"status\": \"NOT_FOUND\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import requests\n",
    "\n",
    "API_KEY = \"AIzaSyBYDxv5LCDXiWSU0uoANX1UmlNpF8WGKBs\"\n",
    "INPUT_PDF = \"input/1WhatsApp Image.pdf\"\n",
    "TESSERACT_CONFIG = \"--psm 6\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    images = convert_from_path(pdf_path)\n",
    "    text = \"\"\n",
    "    for img in images:\n",
    "        text += pytesseract.image_to_string(img, config=TESSERACT_CONFIG)\n",
    "    return text\n",
    "\n",
    "def get_discount_from_llm(text, api_key):\n",
    "    # Example Google LLM API endpoint (fictional placeholder)\n",
    "    url = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText?key=\" + api_key\n",
    "\n",
    "    prompt = f\"Given this invoice/product info, calculate the discount:\\n\\n{text}\\n\\nDiscount:\"\n",
    "    payload = {\n",
    "        \"prompt\": {\n",
    "            \"text\": prompt\n",
    "        },\n",
    "        \"temperature\": 0.7,\n",
    "        \"maxOutputTokens\": 100\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Assuming response has a 'candidates' list with 'output' text\n",
    "        discount_info = data['candidates'][0]['output']\n",
    "        return discount_info\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\"\n",
    "\n",
    "def main():\n",
    "    text = extract_text_from_pdf(INPUT_PDF)\n",
    "    discount = get_discount_from_llm(text, API_KEY)\n",
    "    print(\"Discount info from LLM:\\n\", discount)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee286dc-0c43-446b-862c-47cf40fd9ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
